{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "33515bc9",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'v2_preprocessor'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mPreprocessing\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata_clean\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m remove_221_rows, dropping_no_betting_data, josh_features, fill_f_pm_01m, class_or_rating_average, oli_features\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mv2_preprocessor\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m preprocess_features_v2\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      5\u001b[0m data  \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../raw_data/raw_data_v2.2.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'v2_preprocessor'"
     ]
    }
   ],
   "source": [
    "from Preprocessing.data_clean import remove_221_rows, dropping_no_betting_data, josh_features, fill_f_pm_01m, class_or_rating_average, oli_features\n",
    "from v2_preprocessor import preprocess_features_v2\n",
    "import pandas as pd\n",
    "\n",
    "data  = pd.read_csv(\"../raw_data/raw_data_v2.2.csv\")\n",
    "\n",
    "data_cleaned = remove_221_rows(data)\n",
    "data_cleaned = dropping_no_betting_data(data_cleaned)\n",
    "data_cleaned = josh_features(data_cleaned)\n",
    "data_cleaned = class_or_rating_average(data_cleaned)\n",
    "data_cleaned = oli_features(data_cleaned)\n",
    "data_cleaned = fill_f_pm_01m(data_cleaned)\n",
    "\n",
    "\n",
    "\n",
    "preprocessed_data = preprocess_features_v2(data_cleaned)\n",
    "\n",
    "preprocessed_data.to_csv(\"../raw_data/data_cleaned_and_preprocessed.csv\", index=False)\n",
    "\n",
    "data = pd.read_csv(\"../raw_data/data_cleaned_and_preprocessed.csv\")\n",
    "data.sort_values(by='f_ko')\n",
    "data = data[(data['f_pm_01m'] <= 25)]\n",
    "data = data.reset_index(drop=True)\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d7caa17",
   "metadata": {},
   "outputs": [],
   "source": [
    "backtest = data[['f_ko','f_id', 'id','f_horse','f_pm_01m', 'linear_target', 'f_place']]\n",
    "\n",
    "# #X = data[['f_runners','or_rating_vs_avg_race', 'stall_position', \n",
    "#           'iv_horse_at', 'iv_trainer_l200r', 'iv_trainer_l50r', 'iv_trainer_l16r', 'iv_trainer_at',\n",
    "#           'iv_jockey_l200r', 'iv_jockey_l50r', 'iv_jockey_l16r', 'iv_jockey_at',\n",
    "#           'ae_horse_l10r', 'ae_horse_l5r' , 'ae_horse_l2r' ,'ae_horse_at',\n",
    "#           'ae_trainer_l200r' , 'ae_trainer_l50r' , 'ae_trainer_l16r' , 'ae_trainer_at',\n",
    "#           'ae_jockey_l200r' , 'ae_jockey_l50r', 'ae_jockey_l16r' , 'ae_jockey_at' , 'f_dob', 'f_prb_avg', 'pred_isp']]\n",
    "\n",
    "\n",
    "\n",
    "X = data[['stall_position', \n",
    "          'iv_trainer_l200r', 'iv_jockey_l200r',\n",
    "          'ae_trainer_l200r' ,'ae_jockey_l200r', \n",
    "          'iv_trainer_at', 'iv_jockey_at',\n",
    "          'ae_trainer_at' ,'ae_jockey_at',\n",
    "          'iv_trainer_l50r', 'iv_jockey_l50r',\n",
    "          'ae_trainer_l50r' ,'ae_jockey_l50r',\n",
    "          'iv_trainer_l16r', 'iv_jockey_l16r',\n",
    "          'ae_trainer_l16r' ,'ae_jockey_l16r','pred_isp']]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "y = data[\"f_place\"] #OR 'linear_target'\n",
    "\n",
    "print(data.shape)\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "print(backtest.shape)\n",
    "\n",
    "#Train = Year 1\n",
    "#Val = Year 2\n",
    "#Test = Year 3 (6 months)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1facbc1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X.iloc[:33243]\n",
    "X_val = X.iloc[33243:66406]\n",
    "X_test = X.iloc[66406:]\n",
    "y_train = y.iloc[:33243]\n",
    "y_val = y.iloc[33243:66406]\n",
    "y_test = y.iloc[66406:]\n",
    "backtest_train = backtest.iloc[:33243]\n",
    "backtest_val = backtest.iloc[33243:66406]\n",
    "backtest_test = backtest.iloc[66406:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d28a945",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c3d693b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#buggy data = 2532754    2021-06-20 03:55:00\n",
    "                #29406    20-06-14 18:45:00"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d580cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert labels to a one-hot vector\n",
    "# from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# train_labels = to_categorical(train_labels)\n",
    "# test_labels = to_categorical(test_labels)\n",
    "\n",
    "# define network architecture\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import InputLayer\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.metrics import Precision, Accuracy, Recall, F1Score\n",
    "from tensorflow.keras.losses import Poisson\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "MLP2 = Sequential()\n",
    "MLP2.add(InputLayer(input_shape=(18, ))) # input layer\n",
    "MLP2.add(Dense(32, activation='relu')) # hidden layer 1\n",
    "MLP2.add(Dense(1, activation='sigmoid')) # output layer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36e81d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimization\n",
    "MLP2.compile(loss='binary_focal_crossentropy',\n",
    "            optimizer=Adam(learning_rate = 0.0001),\n",
    "            metrics=['squared_hinge'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b45eab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "# train (fit)\n",
    "\n",
    "es = EarlyStopping(patience=5, restore_best_weights=True)\n",
    "\n",
    "history = MLP2.fit(X_train, y_train, \n",
    "                  epochs=200, batch_size=32, verbose=1,\n",
    "                  validation_data=(X_val, y_val), callbacks = [es], shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30458bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate performance on test data\n",
    "a = MLP2.evaluate(X_test, y_test,\n",
    "                                         verbose=1)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1105c327",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = MLP2.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f22f9e2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f540b3ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.histplot(y_pred, bins = 50, kde=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e33467fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "backtest_test['model_preds'] = y_pred\n",
    "backtest_test['odds_preds'] = 1/ backtest_test['f_pm_01m']\n",
    "backtest_test['model_edge_basic'] = backtest_test['model_preds'] - backtest_test['odds_preds']\n",
    "backtest_test['model_edge_proportionate'] = backtest_test['model_preds'] / backtest_test['odds_preds']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f764a21d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#backtest_test = backtest_test.drop(columns=['f_ko'])\n",
    "model_preds_race = backtest_test.groupby('f_id').sum().reset_index()\n",
    "model_preds_race2 = model_preds_race[['f_id', 'model_preds', 'odds_preds']]\n",
    "dict_odds_preds = model_preds_race2.set_index('f_id')['odds_preds'].to_dict()\n",
    "dict_race_preds = model_preds_race2.set_index('f_id')['model_preds'].to_dict()\n",
    "backtest_test['race_model_preds'] = backtest_test['f_id'].map(dict_race_preds)\n",
    "backtest_test['race_odds_preds'] = backtest_test['f_id'].map(dict_odds_preds)\n",
    "backtest_test['model_preds_scaled'] = (backtest_test['model_preds'] / backtest_test['race_model_preds']) * backtest_test['race_odds_preds']\n",
    "backtest_test['model_edge_basic_scaled'] = backtest_test['model_preds_scaled'] - backtest_test['odds_preds']\n",
    "backtest_test['model_edge_prop_scaled'] = backtest_test['model_preds_scaled'] / backtest_test['odds_preds']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f5594a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataframes of horses above specific proba_difference thresholds\n",
    "\n",
    "all_bets = backtest_test\n",
    "above0 = backtest_test[backtest_test['model_edge_basic_scaled'] >= 0]\n",
    "above5 = backtest_test[backtest_test['model_edge_basic_scaled'] >= 0.025]\n",
    "above10 = backtest_test[backtest_test['model_edge_basic_scaled'] >= 0.05]\n",
    "above15 = backtest_test[backtest_test['model_edge_basic_scaled'] >= 0.075]\n",
    "above20 = backtest_test[backtest_test['model_edge_basic_scaled'] >= 0.10]\n",
    "above30 = backtest_test[backtest_test['model_edge_basic_scaled'] >= 0.20]\n",
    "\n",
    "# Calculate evolutions of profits for each threshold\n",
    "\n",
    "dfall = all_bets\n",
    "dfall['cumulative_profit'] = dfall['linear_target'].cumsum()\n",
    "\n",
    "df0 = above0\n",
    "df0['cumulative_profit'] = df0['linear_target'].cumsum()\n",
    "\n",
    "df5 = above5\n",
    "df5['cumulative_profit'] = df5['linear_target'].cumsum()\n",
    "\n",
    "df10 = above10\n",
    "df10['cumulative_profit'] = df10['linear_target'].cumsum()\n",
    "\n",
    "df15 = above15\n",
    "df15['cumulative_profit'] = df15['linear_target'].cumsum()\n",
    "\n",
    "df20 = above20\n",
    "df20['cumulative_profit'] = df20['linear_target'].cumsum()\n",
    "\n",
    "df30 = above30\n",
    "df30['cumulative_profit'] = df30['linear_target'].cumsum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e4eff44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataframes of horses above specific proba_difference thresholds\n",
    "\n",
    "all_bets = backtest_test\n",
    "above0b = backtest_test[backtest_test['model_edge_basic'] >= 0]\n",
    "above5b = backtest_test[backtest_test['model_edge_basic'] >= 0.05]\n",
    "above10b = backtest_test[backtest_test['model_edge_basic'] >= 0.1]\n",
    "above15b = backtest_test[backtest_test['model_edge_basic'] >= 0.15]\n",
    "above20b = backtest_test[backtest_test['model_edge_basic'] >= 0.20]\n",
    "above30b = backtest_test[backtest_test['model_edge_basic'] >= 0.30]\n",
    "\n",
    "# Calculate evolutions of profits for each threshold\n",
    "\n",
    "dfall = all_bets\n",
    "dfall['cumulative_profit'] = dfall['linear_target'].cumsum()\n",
    "\n",
    "df0b = above0b\n",
    "df0b['cumulative_profit'] = df0b['linear_target'].cumsum()\n",
    "\n",
    "df5b = above5b\n",
    "df5b['cumulative_profit'] = df5b['linear_target'].cumsum()\n",
    "\n",
    "df10b = above10b\n",
    "df10b['cumulative_profit'] = df10b['linear_target'].cumsum()\n",
    "\n",
    "df15b = above15b\n",
    "df15b['cumulative_profit'] = df15b['linear_target'].cumsum()\n",
    "\n",
    "df20b = above20b\n",
    "df20b['cumulative_profit'] = df20b['linear_target'].cumsum()\n",
    "\n",
    "df30b = above30b\n",
    "df30b['cumulative_profit'] = df30b['linear_target'].cumsum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a76d2bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# Plot\n",
    "plt.figure(figsize=(10,6))\n",
    "#plt.plot(range(1, len(dfall) + 1), dfall['cumulative_profit'], label='all bets')\n",
    "#plt.plot(range(1, len(df0) + 1), df0['cumulative_profit'], label='0 threshold')\n",
    "plt.plot(range(1, len(df5) + 1), df5['cumulative_profit'], label='2.5 threshold')\n",
    "plt.plot(range(1, len(df10) + 1), df10['cumulative_profit'], label='5 threshold')\n",
    "plt.plot(range(1, len(df15) + 1), df15['cumulative_profit'], label='7.5 threshold')\n",
    "plt.plot(range(1, len(df20) + 1), df20['cumulative_profit'], label='10 threshold')\n",
    "plt.plot(range(1, len(df30) + 1), df30['cumulative_profit'], label='20 threshold')\n",
    "#plt.plot(range(1, len(df5b) + 1), df5b['cumulative_profit'], label='5 threshold unscaled')\n",
    "#plt.plot(range(1, len(df10b) + 1), df10b['cumulative_profit'], label='10 threshold unscaled')\n",
    "#plt.plot(range(1, len(df15b) + 1), df15b['cumulative_profit'], label='15 threshold unscaled')\n",
    "#plt.plot(range(1, len(df20b) + 1), df20b['cumulative_profit'], label='20 threshold unscaled')\n",
    "#plt.plot(range(1, len(df30b) + 1), df30b['cumulative_profit'], label='30 threshold unscaled')\n",
    "\n",
    "plt.title(\"xxx\")\n",
    "plt.xlabel(\"number of bets\")\n",
    "plt.ylabel(\"profit (£)\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba5e6645",
   "metadata": {},
   "outputs": [],
   "source": [
    "# åplt.hist(backtest_test['model_edge_proportionate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20e87f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create dataframes of horses above specific proba_difference thresholds\n",
    "\n",
    "# all_bets = backtest_test\n",
    "# above0c = backtest_test[backtest_test['model_edge_proportionate'] >= 1]\n",
    "# above5c = backtest_test[backtest_test['model_edge_proportionate'] >= 1.125]\n",
    "# above10c = backtest_test[backtest_test['model_edge_proportionate'] >= 1.25]\n",
    "# above15c = backtest_test[backtest_test['model_edge_proportionate'] >= 1.375]\n",
    "# above20c = backtest_test[backtest_test['model_edge_proportionate'] >= 1.5]\n",
    "# above30c = backtest_test[backtest_test['model_edge_proportionate'] >= 1.75]\n",
    "\n",
    "# # Calculate evolutions of profits for each threshold\n",
    "\n",
    "# dfall = all_bets\n",
    "# dfall['cumulative_profit'] = dfall['linear_target'].cumsum()\n",
    "\n",
    "# df0c = above0c\n",
    "# df0c['cumulative_profit'] = df0c['linear_target'].cumsum()\n",
    "\n",
    "# df5c = above5c\n",
    "# df5c['cumulative_profit'] = df5c['linear_target'].cumsum()\n",
    "\n",
    "# df10c = above10c\n",
    "# df10c['cumulative_profit'] = df10c['linear_target'].cumsum()\n",
    "\n",
    "# df15c = above15c\n",
    "# df15c['cumulative_profit'] = df15c['linear_target'].cumsum()\n",
    "\n",
    "# df20c = above20c\n",
    "# df20c['cumulative_profit'] = df20c['linear_target'].cumsum()\n",
    "\n",
    "# df30c = above30c\n",
    "# df30c['cumulative_profit'] = df30c['linear_target'].cumsum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b79d8e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create dataframes of horses above specific proba_difference thresholds\n",
    "\n",
    "# all_bets = backtest_test\n",
    "# above0d = backtest_test[backtest_test['model_edge_prop_scaled'] >= 1]\n",
    "# above5d = backtest_test[backtest_test['model_edge_prop_scaled'] >= 1.05]\n",
    "# above10d = backtest_test[backtest_test['model_edge_prop_scaled'] >= 1.1]\n",
    "# above15d = backtest_test[backtest_test['model_edge_prop_scaled'] >= 1.15]\n",
    "# above20d = backtest_test[backtest_test['model_edge_prop_scaled'] >= 1.2]\n",
    "# above30d = backtest_test[backtest_test['model_edge_prop_scaled'] >= 1.25]\n",
    "\n",
    "# # Calculate evolutions of profits for each threshold\n",
    "\n",
    "# dfall = all_bets\n",
    "# dfall['cumulative_profit'] = dfall['linear_target'].cumsum()\n",
    "\n",
    "# df0d = above0d\n",
    "# df0d['cumulative_profit'] = df0c['linear_target'].cumsum()\n",
    "\n",
    "# df5d = above5d\n",
    "# df5d['cumulative_profit'] = df5c['linear_target'].cumsum()\n",
    "\n",
    "# df10d = above10d\n",
    "# df10d['cumulative_profit'] = df10c['linear_target'].cumsum()\n",
    "\n",
    "# df15d = above15d\n",
    "# df15d['cumulative_profit'] = df15c['linear_target'].cumsum()\n",
    "\n",
    "# df20d = above20d\n",
    "# df20d['cumulative_profit'] = df20c['linear_target'].cumsum()\n",
    "\n",
    "# df30d = above30d\n",
    "# df30d['cumulative_profit'] = df30c['linear_target'].cumsum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e92931cb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# # Plot\n",
    "# plt.figure(figsize=(10,6))\n",
    "# #plt.plot(range(1, len(dfall) + 1), dfall['cumulative_profit'], label='all bets')\n",
    "# #plt.plot(range(1, len(df0d) + 1), df0d['cumulative_profit'], label='1 threshold')\n",
    "# #plt.plot(range(1, len(df5d) + 1), df5d['cumulative_profit'], label='1.125 threshold')\n",
    "# plt.plot(range(1, len(df10d) + 1), df10d['cumulative_profit'], label='1.25 threshold')\n",
    "# plt.plot(range(1, len(df15d) + 1), df15d['cumulative_profit'], label='1.375 threshold')\n",
    "# plt.plot(range(1, len(df20d) + 1), df20d['cumulative_profit'], label='1.5 threshold')\n",
    "# plt.plot(range(1, len(df30d) + 1), df30d['cumulative_profit'], label='1.75 threshold')\n",
    "# #plt.plot(range(1, len(df5c) + 1), df5c['cumulative_profit'], label='1.05 threshold unscaled')\n",
    "# #plt.plot(range(1, len(df10c) + 1), df10c['cumulative_profit'], label='1.1 threshold unscaled')\n",
    "# #plt.plot(range(1, len(df15c) + 1), df15c['cumulative_profit'], label='1.15 threshold unscaled')\n",
    "# #plt.plot(range(1, len(df20c) + 1), df20c['cumulative_profit'], label='1.2 threshold unscaled')\n",
    "# #plt.plot(range(1, len(df30c) + 1), df30c['cumulative_profit'], label='1.25 threshold unscaled')\n",
    "\n",
    "# plt.title(\"xxx\")\n",
    "# plt.xlabel(\"number of bets\")\n",
    "# plt.ylabel(\"profit (£)\")\n",
    "# plt.legend()\n",
    "# plt.grid(True)\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06d6f4d4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

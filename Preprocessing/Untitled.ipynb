{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8cd631d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/w6/wdkqbmf17b90n_r35p0cb7x00000gn/T/ipykernel_20024/3225624684.py:5: DtypeWarning: Columns (19) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data  = pd.read_csv(\"../raw_data/raw_data_v2.2.csv\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first 221 rows removed. New shape = (118354, 116)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/joshstone/code/lucasglanville/and_theyre_off_backend/Preprocessing/data_clean.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[columns_to_impute] = data[columns_to_impute].apply(impute_row, axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned up missing odds. New shape = (118093, 116)\n",
      "Added Josh features. New shape = (118093, 123)\n",
      "Added Oli features 2/4. New shape = (118093, 125)\n",
      "Added Oli features 4/4. New shape = (118093, 127)\n",
      "number of columns:  128\n",
      "✅ DROPPED IRRELEVANT COLUMNS\n",
      "✅ DROPPED ROWS WITH NULL VALUES\n",
      "✅ WHITESPACE STRIPPED FROM 'f_track'\n",
      "✅ ODDS CONVERTED TO PROBABILITY (1/ODDS)\n",
      "✅ WINNERS CODED AS '1', REST '0'\n",
      "✅ 'f_ko' CONVERTED TO DATETIME\n",
      "✅ TRACK CONDITIONS ORDINALLY ENCODED\n",
      "✅ NUMERIC FEATURES MINMAX-SCALED\n",
      "✅ IMPUTED 'no_headgear' for NULLS IN 'f_headgear'\n",
      "✅ IMPUTED MEAN FOR NULLS IN 'f_dob' & 'f_prb_avg'\n",
      "✅ IMPUTED '0' FOR NULLS IN 68 x FEATURES\n",
      "✅ CAT. FEATURES OH-ENCODED (Track, Headgear, Country)\n",
      "number of columns:  88\n",
      "✅ COLUMN TRANSFORMER ASSEMBLED\n",
      "⏳ FIT_TRANSFORMING THE PREPROCESSING PIPE...\n",
      "number of columns:  164\n",
      "✅ DATA PROCESSED WITH SHAPE: (117468, 164)\n"
     ]
    }
   ],
   "source": [
    "from data_clean import remove_221_rows, dropping_no_betting_data, josh_features, fill_f_pm_01m, class_or_rating_average, oli_features\n",
    "from v2_preprocessor import preprocess_features_v2\n",
    "import pandas as pd\n",
    "\n",
    "data  = pd.read_csv(\"../raw_data/raw_data_v2.2.csv\")\n",
    "\n",
    "data_cleaned = remove_221_rows(data)\n",
    "data_cleaned = dropping_no_betting_data(data_cleaned)\n",
    "data_cleaned = josh_features(data_cleaned)\n",
    "data_cleaned = class_or_rating_average(data_cleaned)\n",
    "data_cleaned = oli_features(data_cleaned)\n",
    "data_cleaned = fill_f_pm_01m(data_cleaned)\n",
    "\n",
    "\n",
    "\n",
    "preprocessed_data = preprocess_features_v2(data_cleaned)\n",
    "\n",
    "preprocessed_data.to_csv(\"../raw_data/data_cleaned_and_preprocessed.csv\", index=False)\n",
    "\n",
    "data = pd.read_csv(\"../raw_data/data_cleaned_and_preprocessed.csv\")\n",
    "data.sort_values(by='f_ko')\n",
    "data = data.reset_index(drop=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7f166593",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1b42da23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f_going</th>\n",
       "      <th>average_or_rating_class</th>\n",
       "      <th>above_below_official_rating_class</th>\n",
       "      <th>PreviousPosition</th>\n",
       "      <th>PredictedRank</th>\n",
       "      <th>f_distance</th>\n",
       "      <th>f_class</th>\n",
       "      <th>f_age</th>\n",
       "      <th>f_pace</th>\n",
       "      <th>f_weight</th>\n",
       "      <th>f_runners</th>\n",
       "      <th>f_rating_or</th>\n",
       "      <th>mean_f_rating_or_race</th>\n",
       "      <th>or_rating_vs_avg_race</th>\n",
       "      <th>f_rating_rbd</th>\n",
       "      <th>f_stall</th>\n",
       "      <th>stall_position</th>\n",
       "      <th>trainer_runs_win_at</th>\n",
       "      <th>trainer_runs_win_l200r</th>\n",
       "      <th>trainer_runs_win_l50r</th>\n",
       "      <th>trainer_runs_win_l16r</th>\n",
       "      <th>trainer_runs_at</th>\n",
       "      <th>trainer_runs_l200r</th>\n",
       "      <th>trainer_runs_l50r</th>\n",
       "      <th>trainer_runs_l16r</th>\n",
       "      <th>jockey_runs_win_at</th>\n",
       "      <th>jockey_runs_win_l200r</th>\n",
       "      <th>jockey_runs_win_l50r</th>\n",
       "      <th>jockey_runs_win_l16r</th>\n",
       "      <th>jockey_runs_at</th>\n",
       "      <th>jockey_runs_l200r</th>\n",
       "      <th>jockey_runs_l50r</th>\n",
       "      <th>jockey_runs_l16r</th>\n",
       "      <th>horse_runs_win_at</th>\n",
       "      <th>horse_runs_win_l10r</th>\n",
       "      <th>horse_runs_win_l5r</th>\n",
       "      <th>horse_runs_win_l2r</th>\n",
       "      <th>horse_runs_at</th>\n",
       "      <th>horse_runs_l10r</th>\n",
       "      <th>horse_runs_l5r</th>\n",
       "      <th>horse_runs_l2r</th>\n",
       "      <th>iv_horse_at</th>\n",
       "      <th>iv_trainer_l200r</th>\n",
       "      <th>iv_trainer_l50r</th>\n",
       "      <th>iv_trainer_l16r</th>\n",
       "      <th>iv_trainer_at</th>\n",
       "      <th>iv_jockey_l200r</th>\n",
       "      <th>iv_jockey_l50r</th>\n",
       "      <th>iv_jockey_l16r</th>\n",
       "      <th>iv_jockey_at</th>\n",
       "      <th>ae_horse_l10r</th>\n",
       "      <th>ae_horse_l5r</th>\n",
       "      <th>ae_horse_l2r</th>\n",
       "      <th>ae_horse_at</th>\n",
       "      <th>ae_trainer_l200r</th>\n",
       "      <th>ae_trainer_l50r</th>\n",
       "      <th>ae_trainer_l16r</th>\n",
       "      <th>ae_trainer_at</th>\n",
       "      <th>ae_jockey_l200r</th>\n",
       "      <th>ae_jockey_l50r</th>\n",
       "      <th>ae_jockey_l16r</th>\n",
       "      <th>ae_jockey_at</th>\n",
       "      <th>rolling_avg_trainer_finish_at</th>\n",
       "      <th>rolling_avg_trainer_finish_l200r</th>\n",
       "      <th>rolling_avg_trainer_finish_l50r</th>\n",
       "      <th>rolling_avg_trainer_finish_l16r</th>\n",
       "      <th>rolling_avg_horse_finish_at</th>\n",
       "      <th>rolling_avg_horse_finish_l10r</th>\n",
       "      <th>rolling_avg_horse_finish_l5r</th>\n",
       "      <th>rolling_avg_horse_finish_l2r</th>\n",
       "      <th>rolling_avg_jockey_finish_at</th>\n",
       "      <th>rolling_avg_jockey_finish_l200r</th>\n",
       "      <th>rolling_avg_jockey_finish_l50r</th>\n",
       "      <th>rolling_avg_jockey_finish_l16r</th>\n",
       "      <th>f_track_ASCOT</th>\n",
       "      <th>f_track_AYR</th>\n",
       "      <th>f_track_BALLINROBE</th>\n",
       "      <th>f_track_BATH</th>\n",
       "      <th>f_track_BELLEWSTOWN</th>\n",
       "      <th>f_track_BEVERLEY</th>\n",
       "      <th>f_track_BRIGHTON</th>\n",
       "      <th>f_track_CARLISLE</th>\n",
       "      <th>f_track_CATTERICK</th>\n",
       "      <th>f_track_CHELMSFORD CITY</th>\n",
       "      <th>f_track_CHEPSTOW</th>\n",
       "      <th>f_track_CHESTER</th>\n",
       "      <th>f_track_CLONMEL</th>\n",
       "      <th>f_track_CORK</th>\n",
       "      <th>f_track_CURRAGH</th>\n",
       "      <th>f_track_DONCASTER</th>\n",
       "      <th>f_track_DOWN ROYAL</th>\n",
       "      <th>f_track_DUNDALK</th>\n",
       "      <th>f_track_EPSOM</th>\n",
       "      <th>f_track_FAIRYHOUSE</th>\n",
       "      <th>f_track_FFOS LAS</th>\n",
       "      <th>f_track_GALWAY</th>\n",
       "      <th>f_track_GOODWOOD</th>\n",
       "      <th>f_track_GOWRAN PARK</th>\n",
       "      <th>f_track_HAMILTON</th>\n",
       "      <th>f_track_HAYDOCK</th>\n",
       "      <th>f_track_KEMPTON</th>\n",
       "      <th>f_track_KILLARNEY</th>\n",
       "      <th>f_track_LAYTOWN</th>\n",
       "      <th>f_track_LEICESTER</th>\n",
       "      <th>f_track_LEOPARDSTOWN</th>\n",
       "      <th>f_track_LIMERICK</th>\n",
       "      <th>f_track_LINGFIELD</th>\n",
       "      <th>f_track_LISTOWEL</th>\n",
       "      <th>f_track_MUSSELBURGH</th>\n",
       "      <th>f_track_NAAS</th>\n",
       "      <th>f_track_NAVAN</th>\n",
       "      <th>f_track_NEWBURY</th>\n",
       "      <th>f_track_NEWCASTLE</th>\n",
       "      <th>f_track_NEWMARKET</th>\n",
       "      <th>f_track_NOTTINGHAM</th>\n",
       "      <th>f_track_PONTEFRACT</th>\n",
       "      <th>f_track_PUNCHESTOWN</th>\n",
       "      <th>f_track_REDCAR</th>\n",
       "      <th>f_track_RIPON</th>\n",
       "      <th>f_track_ROSCOMMON</th>\n",
       "      <th>f_track_SALISBURY</th>\n",
       "      <th>f_track_SANDOWN</th>\n",
       "      <th>f_track_SLIGO</th>\n",
       "      <th>f_track_SOUTHWELL</th>\n",
       "      <th>f_track_THIRSK</th>\n",
       "      <th>f_track_THURLES</th>\n",
       "      <th>f_track_TIPPERARY</th>\n",
       "      <th>f_track_TRAMORE</th>\n",
       "      <th>f_track_WETHERBY</th>\n",
       "      <th>f_track_WINDSOR</th>\n",
       "      <th>f_track_WOLVERHAMPTON</th>\n",
       "      <th>f_track_YARMOUTH</th>\n",
       "      <th>f_track_YORK</th>\n",
       "      <th>f_headgear_B</th>\n",
       "      <th>f_headgear_BC</th>\n",
       "      <th>f_headgear_C</th>\n",
       "      <th>f_headgear_EB</th>\n",
       "      <th>f_headgear_ET</th>\n",
       "      <th>f_headgear_H</th>\n",
       "      <th>f_headgear_HB</th>\n",
       "      <th>f_headgear_HC</th>\n",
       "      <th>f_headgear_HE</th>\n",
       "      <th>f_headgear_HT</th>\n",
       "      <th>f_headgear_HV</th>\n",
       "      <th>f_headgear_T</th>\n",
       "      <th>f_headgear_TB</th>\n",
       "      <th>f_headgear_TC</th>\n",
       "      <th>f_headgear_TV</th>\n",
       "      <th>f_headgear_V</th>\n",
       "      <th>f_headgear_VC</th>\n",
       "      <th>f_headgear_no_headgear</th>\n",
       "      <th>country_GB</th>\n",
       "      <th>country_IRE</th>\n",
       "      <th>f_dob</th>\n",
       "      <th>f_prb_avg</th>\n",
       "      <th>id</th>\n",
       "      <th>f_id</th>\n",
       "      <th>f_ko</th>\n",
       "      <th>f_horse</th>\n",
       "      <th>pred_isp</th>\n",
       "      <th>f_place</th>\n",
       "      <th>f_pm_01m</th>\n",
       "      <th>f_pm_01m_p_back</th>\n",
       "      <th>linear_target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.4</td>\n",
       "      <td>0.836105</td>\n",
       "      <td>0.643877</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.21875</td>\n",
       "      <td>0.15625</td>\n",
       "      <td>0.703704</td>\n",
       "      <td>0.850515</td>\n",
       "      <td>0.597311</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.027778</td>\n",
       "      <td>0.148019</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001919</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.3125</td>\n",
       "      <td>0.004219</td>\n",
       "      <td>0.019231</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.001053</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.499485</td>\n",
       "      <td>0.499484</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.478974</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.014276</td>\n",
       "      <td>0.014276</td>\n",
       "      <td>0.014276</td>\n",
       "      <td>0.014276</td>\n",
       "      <td>0.231883</td>\n",
       "      <td>0.231883</td>\n",
       "      <td>0.231883</td>\n",
       "      <td>0.231883</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.404181</td>\n",
       "      <td>0.434968</td>\n",
       "      <td>16149939000396</td>\n",
       "      <td>16149939000030</td>\n",
       "      <td>2021-03-06 01:25:00</td>\n",
       "      <td>Tone The Barone</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0</td>\n",
       "      <td>2.28</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.4</td>\n",
       "      <td>0.836105</td>\n",
       "      <td>0.691321</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.34375</td>\n",
       "      <td>0.15625</td>\n",
       "      <td>0.755556</td>\n",
       "      <td>0.850515</td>\n",
       "      <td>0.645049</td>\n",
       "      <td>0.845238</td>\n",
       "      <td>0.138889</td>\n",
       "      <td>0.480479</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000768</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.1250</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.195652</td>\n",
       "      <td>0.195652</td>\n",
       "      <td>0.195652</td>\n",
       "      <td>0.195652</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.404181</td>\n",
       "      <td>0.434968</td>\n",
       "      <td>16149939000058</td>\n",
       "      <td>16149939000030</td>\n",
       "      <td>2021-03-06 01:25:00</td>\n",
       "      <td>Blue De Vega</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0</td>\n",
       "      <td>10.00</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   f_going  average_or_rating_class  above_below_official_rating_class  \\\n",
       "0      0.4                 0.836105                           0.643877   \n",
       "1      0.4                 0.836105                           0.691321   \n",
       "\n",
       "   PreviousPosition  PredictedRank  f_distance   f_class  f_age  f_pace  \\\n",
       "0               0.0       0.000000         0.0  0.166667   0.25     0.7   \n",
       "1               0.0       0.032258         0.0  0.166667   0.50     0.5   \n",
       "\n",
       "   f_weight  f_runners  f_rating_or  mean_f_rating_or_race  \\\n",
       "0   0.21875    0.15625     0.703704               0.850515   \n",
       "1   0.34375    0.15625     0.755556               0.850515   \n",
       "\n",
       "   or_rating_vs_avg_race  f_rating_rbd   f_stall  stall_position  \\\n",
       "0               0.597311      0.916667  0.027778        0.148019   \n",
       "1               0.645049      0.845238  0.138889        0.480479   \n",
       "\n",
       "   trainer_runs_win_at  trainer_runs_win_l200r  trainer_runs_win_l50r  \\\n",
       "0                  0.0                     0.0                    0.0   \n",
       "1                  0.0                     0.0                    0.0   \n",
       "\n",
       "   trainer_runs_win_l16r  trainer_runs_at  trainer_runs_l200r  \\\n",
       "0                    0.0         0.001919               0.025   \n",
       "1                    0.0         0.000768               0.010   \n",
       "\n",
       "   trainer_runs_l50r  trainer_runs_l16r  jockey_runs_win_at  \\\n",
       "0               0.10             0.3125            0.004219   \n",
       "1               0.04             0.1250            0.000000   \n",
       "\n",
       "   jockey_runs_win_l200r  jockey_runs_win_l50r  jockey_runs_win_l16r  \\\n",
       "0               0.019231              0.052632                 0.125   \n",
       "1               0.000000              0.000000                 0.000   \n",
       "\n",
       "   jockey_runs_at  jockey_runs_l200r  jockey_runs_l50r  jockey_runs_l16r  \\\n",
       "0        0.001053               0.01              0.04             0.125   \n",
       "1        0.000000               0.00              0.00             0.000   \n",
       "\n",
       "   horse_runs_win_at  horse_runs_win_l10r  horse_runs_win_l5r  \\\n",
       "0                0.0                  0.0                 0.0   \n",
       "1                0.0                  0.0                 0.0   \n",
       "\n",
       "   horse_runs_win_l2r  horse_runs_at  horse_runs_l10r  horse_runs_l5r  \\\n",
       "0                 0.0            0.0              0.0             0.0   \n",
       "1                 0.0            0.0              0.0             0.0   \n",
       "\n",
       "   horse_runs_l2r  iv_horse_at  iv_trainer_l200r  iv_trainer_l50r  \\\n",
       "0             0.0          0.0               0.0              0.0   \n",
       "1             0.0          0.0               0.0              0.0   \n",
       "\n",
       "   iv_trainer_l16r  iv_trainer_at  iv_jockey_l200r  iv_jockey_l50r  \\\n",
       "0              0.0            0.0         0.499485        0.499484   \n",
       "1              0.0            0.0         0.000000        0.000000   \n",
       "\n",
       "   iv_jockey_l16r  iv_jockey_at  ae_horse_l10r  ae_horse_l5r  ae_horse_l2r  \\\n",
       "0             0.5      0.478974            0.0           0.0           0.0   \n",
       "1             0.0      0.000000            0.0           0.0           0.0   \n",
       "\n",
       "   ae_horse_at  ae_trainer_l200r  ae_trainer_l50r  ae_trainer_l16r  \\\n",
       "0          0.0               0.0              0.0              0.0   \n",
       "1          0.0               0.0              0.0              0.0   \n",
       "\n",
       "   ae_trainer_at  ae_jockey_l200r  ae_jockey_l50r  ae_jockey_l16r  \\\n",
       "0            0.0         0.014276        0.014276        0.014276   \n",
       "1            0.0         0.000000        0.000000        0.000000   \n",
       "\n",
       "   ae_jockey_at  rolling_avg_trainer_finish_at  \\\n",
       "0      0.014276                       0.231883   \n",
       "1      0.000000                       0.195652   \n",
       "\n",
       "   rolling_avg_trainer_finish_l200r  rolling_avg_trainer_finish_l50r  \\\n",
       "0                          0.231883                         0.231883   \n",
       "1                          0.195652                         0.195652   \n",
       "\n",
       "   rolling_avg_trainer_finish_l16r  rolling_avg_horse_finish_at  \\\n",
       "0                         0.231883                          0.0   \n",
       "1                         0.195652                          0.0   \n",
       "\n",
       "   rolling_avg_horse_finish_l10r  rolling_avg_horse_finish_l5r  \\\n",
       "0                            0.0                           0.0   \n",
       "1                            0.0                           0.0   \n",
       "\n",
       "   rolling_avg_horse_finish_l2r  rolling_avg_jockey_finish_at  \\\n",
       "0                           0.0                      0.142857   \n",
       "1                           0.0                      0.000000   \n",
       "\n",
       "   rolling_avg_jockey_finish_l200r  rolling_avg_jockey_finish_l50r  \\\n",
       "0                         0.142857                        0.142857   \n",
       "1                         0.000000                        0.000000   \n",
       "\n",
       "   rolling_avg_jockey_finish_l16r  f_track_ASCOT  f_track_AYR  \\\n",
       "0                        0.142857            0.0          0.0   \n",
       "1                        0.000000            0.0          0.0   \n",
       "\n",
       "   f_track_BALLINROBE  f_track_BATH  f_track_BELLEWSTOWN  f_track_BEVERLEY  \\\n",
       "0                 0.0           0.0                  0.0               0.0   \n",
       "1                 0.0           0.0                  0.0               0.0   \n",
       "\n",
       "   f_track_BRIGHTON  f_track_CARLISLE  f_track_CATTERICK  \\\n",
       "0               0.0               0.0                0.0   \n",
       "1               0.0               0.0                0.0   \n",
       "\n",
       "   f_track_CHELMSFORD CITY  f_track_CHEPSTOW  f_track_CHESTER  \\\n",
       "0                      0.0               0.0              0.0   \n",
       "1                      0.0               0.0              0.0   \n",
       "\n",
       "   f_track_CLONMEL  f_track_CORK  f_track_CURRAGH  f_track_DONCASTER  \\\n",
       "0              0.0           0.0              0.0                0.0   \n",
       "1              0.0           0.0              0.0                0.0   \n",
       "\n",
       "   f_track_DOWN ROYAL  f_track_DUNDALK  f_track_EPSOM  f_track_FAIRYHOUSE  \\\n",
       "0                 0.0              0.0            0.0                 0.0   \n",
       "1                 0.0              0.0            0.0                 0.0   \n",
       "\n",
       "   f_track_FFOS LAS  f_track_GALWAY  f_track_GOODWOOD  f_track_GOWRAN PARK  \\\n",
       "0               0.0             0.0               0.0                  0.0   \n",
       "1               0.0             0.0               0.0                  0.0   \n",
       "\n",
       "   f_track_HAMILTON  f_track_HAYDOCK  f_track_KEMPTON  f_track_KILLARNEY  \\\n",
       "0               0.0              0.0              0.0                0.0   \n",
       "1               0.0              0.0              0.0                0.0   \n",
       "\n",
       "   f_track_LAYTOWN  f_track_LEICESTER  f_track_LEOPARDSTOWN  f_track_LIMERICK  \\\n",
       "0              0.0                0.0                   0.0               0.0   \n",
       "1              0.0                0.0                   0.0               0.0   \n",
       "\n",
       "   f_track_LINGFIELD  f_track_LISTOWEL  f_track_MUSSELBURGH  f_track_NAAS  \\\n",
       "0                1.0               0.0                  0.0           0.0   \n",
       "1                1.0               0.0                  0.0           0.0   \n",
       "\n",
       "   f_track_NAVAN  f_track_NEWBURY  f_track_NEWCASTLE  f_track_NEWMARKET  \\\n",
       "0            0.0              0.0                0.0                0.0   \n",
       "1            0.0              0.0                0.0                0.0   \n",
       "\n",
       "   f_track_NOTTINGHAM  f_track_PONTEFRACT  f_track_PUNCHESTOWN  \\\n",
       "0                 0.0                 0.0                  0.0   \n",
       "1                 0.0                 0.0                  0.0   \n",
       "\n",
       "   f_track_REDCAR  f_track_RIPON  f_track_ROSCOMMON  f_track_SALISBURY  \\\n",
       "0             0.0            0.0                0.0                0.0   \n",
       "1             0.0            0.0                0.0                0.0   \n",
       "\n",
       "   f_track_SANDOWN  f_track_SLIGO  f_track_SOUTHWELL  f_track_THIRSK  \\\n",
       "0              0.0            0.0                0.0             0.0   \n",
       "1              0.0            0.0                0.0             0.0   \n",
       "\n",
       "   f_track_THURLES  f_track_TIPPERARY  f_track_TRAMORE  f_track_WETHERBY  \\\n",
       "0              0.0                0.0              0.0               0.0   \n",
       "1              0.0                0.0              0.0               0.0   \n",
       "\n",
       "   f_track_WINDSOR  f_track_WOLVERHAMPTON  f_track_YARMOUTH  f_track_YORK  \\\n",
       "0              0.0                    0.0               0.0           0.0   \n",
       "1              0.0                    0.0               0.0           0.0   \n",
       "\n",
       "   f_headgear_B  f_headgear_BC  f_headgear_C  f_headgear_EB  f_headgear_ET  \\\n",
       "0           0.0            0.0           0.0            0.0            0.0   \n",
       "1           0.0            0.0           0.0            0.0            0.0   \n",
       "\n",
       "   f_headgear_H  f_headgear_HB  f_headgear_HC  f_headgear_HE  f_headgear_HT  \\\n",
       "0           0.0            0.0            0.0            0.0            0.0   \n",
       "1           0.0            0.0            0.0            0.0            0.0   \n",
       "\n",
       "   f_headgear_HV  f_headgear_T  f_headgear_TB  f_headgear_TC  f_headgear_TV  \\\n",
       "0            0.0           1.0            0.0            0.0            0.0   \n",
       "1            0.0           1.0            0.0            0.0            0.0   \n",
       "\n",
       "   f_headgear_V  f_headgear_VC  f_headgear_no_headgear  country_GB  \\\n",
       "0           0.0            0.0                     0.0         1.0   \n",
       "1           0.0            0.0                     0.0         1.0   \n",
       "\n",
       "   country_IRE     f_dob  f_prb_avg              id            f_id  \\\n",
       "0          0.0  0.404181   0.434968  16149939000396  16149939000030   \n",
       "1          0.0  0.404181   0.434968  16149939000058  16149939000030   \n",
       "\n",
       "                  f_ko          f_horse  pred_isp  f_place  f_pm_01m  \\\n",
       "0  2021-03-06 01:25:00  Tone The Barone  0.400000        0      2.28   \n",
       "1  2021-03-06 01:25:00     Blue De Vega  0.222222        0     10.00   \n",
       "\n",
       "   f_pm_01m_p_back  linear_target  \n",
       "0             -1.0           -1.0  \n",
       "1             -1.0           -1.0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8fccd783",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(117468, 164)\n",
      "(117468, 11)\n",
      "(117468,)\n",
      "(117468, 7)\n"
     ]
    }
   ],
   "source": [
    "backtest = data[['f_ko','f_id', 'id','f_horse','f_pm_01m', 'linear_target', 'f_place']]\n",
    "\n",
    "# #X = data[['f_runners','or_rating_vs_avg_race', 'stall_position', \n",
    "#           'iv_horse_at', 'iv_trainer_l200r', 'iv_trainer_l50r', 'iv_trainer_l16r', 'iv_trainer_at',\n",
    "#           'iv_jockey_l200r', 'iv_jockey_l50r', 'iv_jockey_l16r', 'iv_jockey_at',\n",
    "#           'ae_horse_l10r', 'ae_horse_l5r' , 'ae_horse_l2r' ,'ae_horse_at',\n",
    "#           'ae_trainer_l200r' , 'ae_trainer_l50r' , 'ae_trainer_l16r' , 'ae_trainer_at',\n",
    "#           'ae_jockey_l200r' , 'ae_jockey_l50r', 'ae_jockey_l16r' , 'ae_jockey_at' , 'f_dob', 'f_prb_avg', 'pred_isp']]\n",
    "\n",
    "\n",
    "X = data[['f_runners','or_rating_vs_avg_race', 'stall_position', \n",
    "          'iv_trainer_l50r', 'iv_jockey_l50r', 'ae_horse_l5r' ,\n",
    "          'ae_trainer_l50r' ,'ae_jockey_l50r', 'f_dob', 'f_prb_avg', 'pred_isp']]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "y = data[\"linear_target\"] #OR 'linear_target'\n",
    "\n",
    "print(data.shape)\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "print(backtest.shape)\n",
    "\n",
    "#Train = Year 1\n",
    "#Val = Year 2\n",
    "#Test = Year 3 (6 months)\n",
    "\n",
    "\n",
    "X_train = X.iloc[:70000]\n",
    "X_val = X.iloc[70000:91429]\n",
    "X_test = X.iloc[91429:]\n",
    "y_train = y.iloc[:70000]\n",
    "y_val = y.iloc[70000:91429]\n",
    "y_test = y.iloc[91429:]\n",
    "backtest_train = backtest.iloc[:70000]\n",
    "backtest_val = backtest.iloc[70000:91429]\n",
    "backtest_test = backtest.iloc[91429:]\n",
    "\n",
    "#backtesting=data.iloc[91432:]\n",
    "\n",
    "#X_train=X.iloc[:73753]\n",
    "#X_val=X.iloc[73753:91432]\n",
    "#X_test=X.iloc[91432:]\n",
    "#y_train=y.iloc[:73753]\n",
    "#y_val=y.iloc[73753:91432]\n",
    "#y_test=y.iloc[91432:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4bc10f97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f_runners</th>\n",
       "      <th>or_rating_vs_avg_race</th>\n",
       "      <th>stall_position</th>\n",
       "      <th>iv_trainer_l50r</th>\n",
       "      <th>iv_jockey_l50r</th>\n",
       "      <th>ae_horse_l5r</th>\n",
       "      <th>ae_trainer_l50r</th>\n",
       "      <th>ae_jockey_l50r</th>\n",
       "      <th>f_dob</th>\n",
       "      <th>f_prb_avg</th>\n",
       "      <th>pred_isp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>69998</th>\n",
       "      <td>0.09375</td>\n",
       "      <td>0.645829</td>\n",
       "      <td>0.214523</td>\n",
       "      <td>0.100103</td>\n",
       "      <td>0.080495</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.010058</td>\n",
       "      <td>0.007654</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69999</th>\n",
       "      <td>0.09375</td>\n",
       "      <td>0.550352</td>\n",
       "      <td>0.330890</td>\n",
       "      <td>0.200206</td>\n",
       "      <td>0.140351</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.020758</td>\n",
       "      <td>0.013330</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.266667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       f_runners  or_rating_vs_avg_race  stall_position  iv_trainer_l50r  \\\n",
       "69998    0.09375               0.645829        0.214523         0.100103   \n",
       "69999    0.09375               0.550352        0.330890         0.200206   \n",
       "\n",
       "       iv_jockey_l50r  ae_horse_l5r  ae_trainer_l50r  ae_jockey_l50r  f_dob  \\\n",
       "69998        0.080495           0.0         0.010058        0.007654   0.20   \n",
       "69999        0.140351           0.0         0.020758        0.013330   0.38   \n",
       "\n",
       "       f_prb_avg  pred_isp  \n",
       "69998       0.46  0.400000  \n",
       "69999       0.26  0.266667  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.tail(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "08adbb64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70000, 11)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4ccb93ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert labels to a one-hot vector\n",
    "# from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# train_labels = to_categorical(train_labels)\n",
    "# test_labels = to_categorical(test_labels)\n",
    "\n",
    "# define network architecture\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import InputLayer\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.metrics import Precision, Accuracy, Recall\n",
    "\n",
    "MLP = Sequential()\n",
    "MLP.add(InputLayer(input_shape=(11, ))) # input layer\n",
    "MLP.add(Dense(32, activation='relu')) # hidden layer 2\n",
    "MLP.add(Dropout(0.2))\n",
    "MLP.add(Dense(16, activation='relu')) # hidden layer 2\n",
    "MLP.add(Dropout(0.2))\n",
    "MLP.add(Dense(1, activation='linear')) # output layer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3c6f1c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimization\n",
    "MLP.compile(loss='mse',\n",
    "            optimizer='adam',\n",
    "            metrics=['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "64fda79a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1094/1094 [==============================] - 1s 506us/step - loss: 23.2294 - mae: 1.7112 - val_loss: 33.7629 - val_mae: 1.7426\n",
      "Epoch 2/20\n",
      "1094/1094 [==============================] - 1s 463us/step - loss: 23.2231 - mae: 1.7055 - val_loss: 33.7667 - val_mae: 1.7978\n",
      "Epoch 3/20\n",
      "1094/1094 [==============================] - 1s 466us/step - loss: 23.2210 - mae: 1.7098 - val_loss: 33.7616 - val_mae: 1.7614\n",
      "Epoch 4/20\n",
      "1094/1094 [==============================] - 1s 466us/step - loss: 23.2192 - mae: 1.7082 - val_loss: 33.7646 - val_mae: 1.7407\n",
      "Epoch 5/20\n",
      "1094/1094 [==============================] - 1s 462us/step - loss: 23.2185 - mae: 1.7092 - val_loss: 33.7634 - val_mae: 1.7300\n",
      "Epoch 6/20\n",
      "1094/1094 [==============================] - 1s 462us/step - loss: 23.2182 - mae: 1.7019 - val_loss: 33.7623 - val_mae: 1.7449\n",
      "Epoch 7/20\n",
      "1094/1094 [==============================] - 1s 464us/step - loss: 23.2198 - mae: 1.7116 - val_loss: 33.7625 - val_mae: 1.7416\n",
      "Epoch 8/20\n",
      "1094/1094 [==============================] - 1s 465us/step - loss: 23.2186 - mae: 1.7041 - val_loss: 33.7611 - val_mae: 1.7648\n",
      "Epoch 9/20\n",
      "1094/1094 [==============================] - 1s 463us/step - loss: 23.2190 - mae: 1.7131 - val_loss: 33.7627 - val_mae: 1.7457\n",
      "Epoch 10/20\n",
      "1094/1094 [==============================] - 1s 464us/step - loss: 23.2199 - mae: 1.7027 - val_loss: 33.7609 - val_mae: 1.7588\n",
      "Epoch 11/20\n",
      "1094/1094 [==============================] - 1s 461us/step - loss: 23.2187 - mae: 1.7110 - val_loss: 33.7614 - val_mae: 1.7595\n",
      "Epoch 12/20\n",
      "1094/1094 [==============================] - 1s 465us/step - loss: 23.2198 - mae: 1.7087 - val_loss: 33.7615 - val_mae: 1.7591\n",
      "Epoch 13/20\n",
      "1094/1094 [==============================] - 1s 462us/step - loss: 23.2185 - mae: 1.7030 - val_loss: 33.7630 - val_mae: 1.7516\n",
      "Epoch 14/20\n",
      "1094/1094 [==============================] - 1s 463us/step - loss: 23.2183 - mae: 1.6980 - val_loss: 33.7619 - val_mae: 1.7805\n",
      "Epoch 15/20\n",
      "1094/1094 [==============================] - 1s 460us/step - loss: 23.2193 - mae: 1.7164 - val_loss: 33.7627 - val_mae: 1.7550\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "# train (fit)\n",
    "\n",
    "es = EarlyStopping(patience=5, restore_best_weights=True)\n",
    "\n",
    "history = MLP.fit(X_train, y_train, \n",
    "                  epochs=20, batch_size=64, verbose=1,\n",
    "                  validation_data=(X_val, y_val), callbacks = [es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "eaf866fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "407/407 [==============================] - 0s 297us/step - loss: nan - mae: nan\n",
      "Test loss: nan\n",
      "Test mae: nan\n"
     ]
    }
   ],
   "source": [
    "# evaluate performance on test data\n",
    "test_loss, test_acc = MLP.evaluate(X_test, y_test,\n",
    "                                         batch_size=64,\n",
    "                                         verbose=1)\n",
    "print(\"Test loss:\", test_loss)\n",
    "print(\"Test mae:\", test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "96df8880",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "814/814 [==============================] - 0s 227us/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = MLP.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "eac545fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.0384361 ],\n",
       "       [-0.02714098],\n",
       "       [-0.02723045],\n",
       "       ...,\n",
       "       [-0.02859861],\n",
       "       [-0.03887936],\n",
       "       [-0.03644545]], dtype=float32)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c1f67e93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: ylabel='Count'>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "sns.histplot(y_pred, bins = 50, kde=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e52c66b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/w6/wdkqbmf17b90n_r35p0cb7x00000gn/T/ipykernel_20024/1787826085.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  backtest_test['model_preds'] = y_pred\n"
     ]
    }
   ],
   "source": [
    "backtest_test['model_preds'] = y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b4f5584",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "all_bets = backtest_test\n",
    "above0 = backtest_test[backtest_test['model_preds'] >= -0.05]\n",
    "above5 = backtest_test[backtest_test['model_preds'] >= -0.04]\n",
    "above10 = backtest_test[backtest_test['model_preds'] >= -0.03]\n",
    "above15 = backtest_test[backtest_test['model_preds'] >= -0.02]\n",
    "above20 = backtest_test[backtest_test['model_preds'] >= -0.01]\n",
    "above30 = backtest_test[backtest_test['model_preds'] >= 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7ed750eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "2df1cf30",
   "metadata": {},
   "outputs": [],
   "source": [
    "Model2 = SGDRegressor(max_iter=1000, tol=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "66d1d650",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SGDRegressor()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SGDRegressor</label><div class=\"sk-toggleable__content\"><pre>SGDRegressor()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SGDRegressor()"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Model2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "1bc334d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "score = Model2.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "40d0ee56",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.0003220394546066263"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "0bed536a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import scale\n",
    "import matplotlib.pyplot as plt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "0304aefa",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X.iloc[:70000]\n",
    "X_val = X.iloc[70000:91429]\n",
    "X_test = X.iloc[91429:]\n",
    "y_train = y.iloc[:70000]\n",
    "y_val = y.iloc[70000:91429]\n",
    "y_test = y.iloc[91429:]\n",
    "X_trainval = X.iloc[:91429]\n",
    "y_trainval = y.iloc[:91429]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "37e86ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_score = cross_val_score(Model2, X_trainval, y_trainval, cv = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "beec7f91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.00046978492413136675"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_score.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c14adf7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
